{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOYmhFsDiqOFyALmPJzHO1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/workszop/notebooks/blob/main/embedding_cohere_example_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cohere\n",
        "\n",
        "Cohere offers free trial API keys, we can use to chat to their model.\n",
        "\n",
        "[API key](https://dashboard.cohere.com/api-keys)  \n",
        "[API documentation](https://docs.cohere.com/docs/cochat-beta)"
      ],
      "metadata": {
        "id": "TtuYDYuZ_Tae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat"
      ],
      "metadata": {
        "id": "x6FJm4u2ugBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0UFy6XA8Gtz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "key = input('please provide your Cohere API key:\\n')\n",
        "co = cohere.Client(key)"
      ],
      "metadata": {
        "id": "mkrLAYDi8J_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# embedding"
      ],
      "metadata": {
        "id": "kNw32Wrpx6rA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simple animals example"
      ],
      "metadata": {
        "id": "hy0N1mrPAVrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below we create a list of animals and use cohere embedding service to embed them\n",
        "# embadding means turning text into numbers which encode its meaning into multi dimentional space\n",
        "# the number of dimentions depends on the model used\n",
        "# \"embed-english-light-v3.0\" generates 384 dimensions embedding\n",
        "# (each piece of text is represented by 384 numbers)\n",
        "\n",
        "animals = [\"dog\", \"cat\",\"hamster\", \"mouse\", \"horse\", \"cow\", \"pig\",\n",
        "           \"giraffe\", \"elephant\", \"rhinoceros\",\n",
        "           \"wolf\", \"fox\", \"shark\", \"whale\", \"manta\"]\n",
        "\n",
        "\n",
        "model_name = \"embed-english-light-v3.0\"\n",
        "\n",
        "embeds = co.embed(texts=animals,\n",
        "                  model=model_name,\n",
        "                  input_type=\"search_document\").embeddings\n",
        "\n",
        "embeddings = np.array(embeds)\n",
        "print(f'embedding dimensions: {embeddings.shape[1]}')"
      ],
      "metadata": {
        "id": "GnH4VKtfAYjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we use tsne library to transform the embeddigs to 2 dimentional space\n",
        "# it enables us to display them on the screen\n",
        "# please bear in mind that this transformation doesn't preserve all the information\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=2, random_state=42, init='random', learning_rate=200)\n",
        "words_embedded = tsne.fit_transform(embeddings)\n",
        "print(f'dimensions after transformation: {words_embedded.shape[1]}')"
      ],
      "metadata": {
        "id": "ggfxSz0VA6Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of embedding (after dimentionality reduction)\n",
        "# the visualization you see doesn't show all the meaning encoded by embedding\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, label in enumerate(animals):\n",
        "  x, y = words_embedded[i, :]\n",
        "  plt.scatter(x, y)\n",
        "  plt.annotate(label, xy=(x, y), xytext=(5, 5), textcoords='offset points', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.title(\"word embeddings in 2D\")"
      ],
      "metadata": {
        "id": "6IHcqAwFBVGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## various words"
      ],
      "metadata": {
        "id": "nfmoTsAbAR-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['apple', 'pan', 'table', 'fridge', 'soap', 'broom', 'magazine', 'pin',\n",
        "         'necklace', 'bed', 'shirt', 'stapler', 'newspaper', 'briefcase',\n",
        "         'camera', 'mop', 'kettle', 'sponge', 'mug', 'ring', 'socks', 'sandals',\n",
        "         'clock', 'pliers', 'highlighter', 'boots', 'blender',\n",
        "         'microwave', 'helmet', 'computer', 'mouse', 'headphones',\n",
        "         'curtain', 'towel', 'pen', 'duster', 'wrench', 'calculator',\n",
        "         'radio', 'shampoo', 'stove', 'jeans', 'jar', 'glue', 'oven', 'wallet',\n",
        "         'thesaurus', 'gown', 'diary', 'dictionary', 'dress', 'keyboard',\n",
        "         'bicycle', 'bucket', 'envelope', 'blanket', 'marker', 'ruler', 'atlas',\n",
        "         'book', 'truck', 'beanie', 'earrings', 'bottle', 'ten', 'three', 'pencil',\n",
        "         'frame', 'backpack', 'lamp', 'paper', 'can', 'toothpaste', 'spatula',\n",
        "         'calendar', 'cup', 'scarf', 'orange', 'monitor', 'hammer', 'hat', 'drill',\n",
        "         'sneakers', 'tie', 'beret', 'brush', 'swimsuit', 'picture', 'encyclopedia',\n",
        "         'pants', 'purse', 'stamp', 'binder', 'suitcase', 'motorcycle', 'eraser',\n",
        "         'shorts', 'chair', 'fork', 'knife', 'mixer', 'dryer', 'mirror', 'clip',\n",
        "         'one', 'couch', 'saw', 'bolt', 'spoon', 'notebook', 'toaster', 'gloves',\n",
        "         'nail', 'car', 'scissors', 'razor', 'pillow', 'glasses', 'nut', 'coat',\n",
        "         'heels', 'crayon', 'shoes', 'skirt', 'sunglasses', 'pot', 'plate', 'bikini',\n",
        "         'cap', 'television', 'robe', 'washer', 'sweater', 'phone', 'belt',\n",
        "         'screwdriver', 'watch', 'bowl', 'bracelet', 'tape', 'twenty', 'screw',\n",
        "         'vacuum', 'peach', 'notepad', 'pajamas', 'carpet', 'toothbrush', 'band',\n",
        "         'file', 'umbrella', 'box', 'novel', 'printer', 'underwear', 'slippers',\n",
        "         'pear', 'bra', 'card', 'desk', 'thousand', 'jacket', 'folder', 'bag',\n",
        "         'dish', 'bus', 'textbook', 'banana', 'keys']"
      ],
      "metadata": {
        "id": "_rQeSl1FyU5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# below we create a list of animals and use cohere embedding service to embed them\n",
        "# embadding means turning text into numbers which encode its meaning into multi dimentional space\n",
        "# the number of dimentions depends on the model used\n",
        "# \"embed-english-light-v3.0\" generates 384 dimensions embedding\n",
        "# (each piece of text is represented by 384 numbers)\n",
        "\n",
        "model_name = \"embed-english-light-v3.0\"\n",
        "\n",
        "embeds = co.embed(texts=words,\n",
        "                  model=model_name,\n",
        "                  input_type=\"search_document\").embeddings\n",
        "\n",
        "embeddings = np.array(embeds)"
      ],
      "metadata": {
        "id": "zOK6Uc2Cyq12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"rain\"\n",
        "input_type_query = \"search_query\"\n",
        "\n",
        "query_embed = co.embed(texts=[query],\n",
        "                  model=model_name,\n",
        "                  input_type=\"search_query\").embeddings\n",
        "\n",
        "q_embed = np.array(query_embed)"
      ],
      "metadata": {
        "id": "tNO_ctArz-1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(q_embed, embeddings)"
      ],
      "metadata": {
        "id": "Xn-Zn_T-6E-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[np.argmax(cosine_similarity(q_embed, embeddings))]"
      ],
      "metadata": {
        "id": "83st43_f15tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### visualization"
      ],
      "metadata": {
        "id": "z47ojpX5-1ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we use tsne library to transform the embeddigs to 2 dimentional space\n",
        "# it enables us to display them on the screen\n",
        "# please bear in mind that this transformation doesn't preserve all the information\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n",
        "words_embedded = tsne.fit_transform(embeddings)\n",
        "print(words_embedded.shape)"
      ],
      "metadata": {
        "id": "27X7JcOj5_9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of embedding (after dimentionality reduction)\n",
        "# the visualization you see doesn't show all the meaning encoded by embedding\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, label in enumerate(words):\n",
        "  x, y = words_embedded[i, :]\n",
        "  plt.scatter(x, y)\n",
        "  plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
        "\n",
        "plt.title(\"word embeddings in 2D\")"
      ],
      "metadata": {
        "id": "-IWBBaEV9NvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cN6KD1s7-4dU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}